% ispaper.tex - Independent Study I Paper

\documentclass{article}
\usepackage{times}
\usepackage{bytefield}
\usepackage{listings}
\addtolength{\parskip}{\baselineskip}
\usepackage[utf8]{inputenc}

\begin{document}

\title{SQLite Forensics:\\\emph{Exposition on the SQLite File Format and Techniques for Data Carving}}
\date{\today}
\author{ST2602: Computer Forensics\\Singapore Polytechnic\\\\Ku Wee Kiat (P1030284)\\Jeremy Heng (P1000720)\\DISM 3B21/22}
\maketitle

\vfill
\begin{abstract}
The paper will study the SQLite File Specification and propose techniques for fingerprinting and identifying SQLite files in non-coherent data and the recovery of stored information from a SQLite database. It explains how a database file is laid out on the disk and the various physical and logical structures that comprise a SQLite database. In addition, we put forward reasoning for the value of the paper's propositions with regard to its importance in computer forensics. Python scripts accompany this paper as proof-of-concept pieces for the rough implementation of the techniques presented.
\end{abstract}

\pagebreak

\setcounter{tocdepth}{4}
\tableofcontents

\pagebreak
\section{Introduction}

\subsection{Overview}
The paper will study the SQLite File Specification and propose techniques for fingerprinting and identifying SQLite files in non-coherent data and the recovery of stored information from a SQLite database. It explains how a database file is laid out on the disk and the various physical and logical structures that comprise a SQLite database. In addition, we put forward reasoning for the value of the paper's propositions with regard to its importance in computer forensics.

\subsection{Introduction to SQLite}
SQLite is an in-process library that implements a self-contained, serverless, zero-configuration, transactional SQL database engine. This property makes it a very favourable for use in situations where a client side data store is desired. SQLite is used extensively by web browsers like Google Chrome and Firefox to store metadata and user information such as cookies. 

Smartphone operating systems like Android, Symbian, and the iOS use SQLite to store contact lists and SMS messages. This wide usage of SQLite makes it a valuable subject for both forensics investigators and researchers. 

The entire library is distributed and included in applications as a series of C source files or a large 'amalagamated' source and header file for inclusion into an application. It is often statically compiled into the application because of its extremely small size and as a result, performs SQLite operations within its process memory.

\subsection{Motivations}
Since SQLite is so widely used, the authors of this paper intended for this paper to further their, and ultimately, the reader's understanding of the SQLite file format with the intention to develop techniques to fingerprint and carve SQLite files in numerous data sources. 

A side objective was to enable researchers to better develop open source tools towards this goal as we noticed a large number of commercial SQLite forensics tools when compared to an almost non-existent open source scene.

\subsection{Summary of Conclusions}
We had concluded that it was possible to carve table records given data containing a full or partial SQLite file to a degree of corruption. As a proof-of-concept for some techniques put forward, we include Python scripts for use on a sample database file one may create themselves using a supplied set of SQL commands in sqlite3.

\section{SQLite File Format}

This section will describe the SQLite format to an extent that is relevant to carving of SQLite data.

\subsection{SQLite Header}

Every SQLite database begins with a 100 byte header containing crucial metadata. An SQLite file may be identified almost intuitively by its magic signature, ``SQLite format 3\textbackslash x00''. \\

\begin{bytefield}[bitwidth=1.55em]{20}
  \bitheader{0-19} \\
  \bitbox{16}{Magic Numbers ``SQLite format 3\textbackslash x00''} & \bitbox{2}{\tiny Page Size} & \bitbox{1}{\small Wr} & \bitbox{1}{\small Re}\\
  \bitbox{1}{Rs} & \bitbox{1}{Ma} & \bitbox{1}{Mi} & \bitbox{1}{Le} & \bitbox{4}{\small Change Counter} & \bitbox{4}{\small Database Size} & \bitbox{4}{First FTP} \bitbox{4}{Total FTP} \\  
  \bitbox{4}{\small Schema Cookie} & \bitbox{4}{\small Format Number} & \bitbox{4}{\tiny Default Page Cache Size} & \bitbox{4}{\tiny Largest Root B-Tree Page} & \bitbox{4}{Text Encoding}\\
    \bitbox{4}{User Version} & \bitbox{4}{\tiny Incremental Vacuum Mode} & \bitbox[lrt]{12}{Reserved for expansion} \\
    \bitbox[lrb]{12}{} & \bitbox{4}{\tiny Version-Valid-For} & \bitbox{4}{\tiny SQLite Version Number}
\end{bytefield}

As only a few fields of the header are relevant to our ends, we will focus solely on those. Please refer to the official file format specification for descriptions of the other fields. 

The first 16 bytes of the header correspond to the string ``SQLite format 3\textbackslash x00'' and is one of the identifying features of SQLite. Other important fields are: Page size (offset 16), Maximum embedded, minimum, and leaf payload fractions (offsets 21, 22, and 23 respectively), and the In-header database size (offset 28). 

The magic numbers and payload fractions allow us to fingerprint database files while the page size and in-header database size (total number of pages) aid in our carving technique.

\subsection{Pages}

The largest structure in an SQLite file is a page. Pages come in a variety of types: Freelist Pages, Lock-Byte Pages, B-tree Pages, Payload Overflow Pages, and Pointer Map Pages. Pages have a default page size of 1024 bytes.

Only B-tree Pages and Payload Overflow Pages are of carving value, the rest are not relevant to our ends and hence in the remainder of this paper, it is these two types of pages we will focus our attention on. 

There are 4 types of B-tree pages: table interior, table leaf, index interior and index leaf. Table leaf pages are of carving value because they store table content. \\

\begin{bytefield}[bitwidth=1.55em]{18}
  \bitheader{0-17} \\
  \bitbox{8}{ Page Header} & \bitbox{2}{\tiny Cell Ptr 1} & \bitbox{2}{\tiny Cell Ptr 2} & \bitbox{2}{\tiny Cell Ptr 3} & \bitbox{2}{\tiny Cell Ptr 4} & \bitbox{2}{\tiny Cell Ptr 5} &\\
  \wordbox[]{1}{$\vdots$} \\[1ex]
  \bitbox{2}{ \tiny Cell Ptr N} & \bitbox{16}{Unallocated space} \\
  \wordbox[]{1}{$\vdots$} \\[1ex]
  \bitbox{4}{\tiny Unallocated space} & \bitbox{6}{Cell 1}  & \bitbox{8}{Cell 2}\\
  \wordbox[]{1}{$\vdots$} \\[1ex]
  \bitbox{6}{Cell N-1} & \bitbox{6}{Cell N}  & \bitbox{6}{Reserved Space}\\
\end{bytefield}

A table leaf page is comprised of: the 100 byte SQLite header (only on first page), an 8 byte page header, a cell pointer array, unallocated space, and cells. 

Page headers contain metadata about the page. Cell pointer arrays are 2 byte big endian integer offsets arranged in ascending key value that point to cells at the end of page. There will always be an equal number of cell pointers and cells. Cells correspond to rows in the logical database table. The payload of each cell contains a record, the contents of the row (i.e. logical columns).

The reserved region is an unused space reserved for use by extensions to store page specific data. The size of reserved regions are specified by the  1-byte unsigned integer in offset 20 of the 100-byte database header. The size of the reserved region is usually 0.

\subsubsection{Page Header}

The B-tree page header is 8 bytes (or 12 bytes) long depending on the type of the B-tree page, which is detemined by the one byte value at offset 0 of the page header. \\

\begin{bytefield}[bitwidth=4em]{8}
  \bitheader{0-7} \\
  \bitbox{1}{Type} & \bitbox{2}{Freeblock Offset} & \bitbox{2}{No. of Cells} & \bitbox{2}{\small Cell Content Offset} & \bitbox{1}{\tiny Free Bytes} \end{bytefield}

The type field is a flag. The value of this flag determines the type of B-tree page: 0x02 -- interior index page, 0x05 -- interior table page, 0x0A -- leaf index page, and 0x0D -- leaf table page. The freeblock offset points to the first freeblock in the page and is 0 if there are none. The number of cells describe how many cells are contained within the page. This also tells you how many entries are there in the cell pointer array. The cell content offset points to the start of the cells at the end of the page.

In interior B-tree pages offsets 8-12 contain the pointer to the right-most pointer. However, we need not concern ourselves with interior B-tree pages for the scope of this paper hence it is not included in the diagram above.

\subsubsection{Freeblock}

A freeblock is a 4 byte structure within a page that identifies unallocated or unused space within the B-tree page. Multiple freeblocks form a chain.

\begin{bytefield}[bitwidth=8em]{4}
  \bitheader{0-3} \\
  \bitbox{2}{Next Freeblock Offset} & \bitbox{2}{Size in bytes} 
\end{bytefield}

Freeblocks are chained together with the freeblock having the smallest offset at the beginning and ending with the freeblock with the largest offset. The first freeblock may be discovered by looking at offset 1 of the page header. The freeblock offset field points to the next freeblock or is 0 if it is the last freeblock.

A freeblock requires at least 4 bytes of space. Anything that is isolated and has less than 4 bytes of unused space within the cell content area is a fragment. The total number of fragmented bytes is stored in the 5th field (bytes 8-11) of the B-tree page header. Total number of fragmented bytes should not be more than 60 in a well-formed b-tree page.

In a b-tree page, the size of the unallocated region in addition to the total size of all freeblocks and fragmented free bytes equals the total amount of freespace.

SQLite may perform an operation similar to defragmentation on file systems to a b-tree page. It will reorganise the b-tree page to reduce or remove the number of freeblocks or fragmented free bytes in the page. The unused bytes will be contained in the unallocated space region. Cells with data are at the same time moved as tightly as possible to the end of the page.

\subsubsection{Cell Format}

A cell within a page contains a record from a logical table in an SQLite database. This is the level we are most interested in carving. Cells are variably sized.\\

\begin{bytefield}[bitwidth=6.2em]{5}
  \bitheader{0-4} \\
  \bitbox{1}{Payload Size} & \bitbox{1}{Row ID}  & \bitbox{2}{Payload} & \bitbox{1}{Overflow Page}
\end{bytefield}

The payload size and row id is represented as a varint (please see the section on variable length integers for more information). Thus, each of these fields may range from 1 to 9 bytes in length. The payload length is also variable. The overflow page number is encoded as a 4 byte big endian integer.

\subsubsection{Cell Payloads or Records}

Cell payloads are comprised of a header and a body.  \\

\begin{bytefield}[bitwidth=15em]{2}
  \bitheader{0-1} \\
  \bitbox{1}{Header} & \bitbox{1}{Body}
\end{bytefield}

The header contains the header size as well as a variable number of serial types describing the content of the body. The body contains actual record data.\\

\begin{bytefield}[bitwidth=6em]{5}
  \bitheader{0-4} \\
  \bitbox{1}{Header Size} & \bitbox{1}{stype 1} & \bitbox{1}{stype 2} & \bitbox{1}{...} & \bitbox{1}{stype N}
\end{bytefield}

All fields are encoded as varints. Each serial type corresponds to a column in the body. A table as follows describes the length and method of interpretation of the serial types when mapping to values in the body.

\begin{bytefield}[bitwidth=6em]{5}
  \bitheader{0-4} \\
  \bitbox{1}{Value 1} & \bitbox{2}{Value 2} & \bitbox{1}{...} & \bitbox{1}{Value N}
\end{bytefield}

Serial types may be decoded using the following table:

\begin{table}     
  \begin{tabular}{|l|l|l|}         
    \hline         Serial Type   & Content Size & Meaning                                                                                            
\\ \hline         0             & 0            & NULL                                                                                            \\         1             & 1            & 8-bit twos-complement integer                                                                   \\         2             & 2            & Big-endian 16-bit twos-complement integer                                                       \\         3             & 3            & Big-endian 24-bit twos-complement integer                                                       \\         4             & 4            & Big-endian 32-bit twos-complement integer                                                       \\         5             & 6            & Big-endian 48-bit twos-complement integer                                                       \\         6             & 8            & Big-endian 64-bit twos-complement integer                                                       \\         7             & 8            & Big-endian IEEE 754-2008 64-bit floating point number                                           \\         8             & 0            & Integer constant 0.                                                                             \\         9             & 0            & Integer constant 1.                                                                             \\         10, 11        & ~            & Reserved                                                                                        \\         N\geq12 and even & (N-12)/2     & A BLOB that is (N-12)/2 bytes in length                                                         \\         N\geq13 and odd  & (N-13)/2     & A string in the database encoding and (N-13)/2 bytes in length. 
\\         ~             & ~            & ~                                                                                               
\\         
\hline     
\end{tabular} 
\end{table} 

\subsubsection{Overflow Pages}

A page's size is fixed while a record (or payload) size varies, a record's size can be too large to fit in one leaf table b-tree page. For example, if the page size is 1024 bytes and the record’s (payload) is more than 1024 bytes, the record will not be able to fit within a single leaf table b-tree page and will thus be divided to fit into the available payload space in the page and the remainder in one or more overflow pages. 

These pages form a linked list. The first 4-byte big endian integer 'overflow page no.' field in the overflow page indicates the next overflow page in the chain. If its the last overflow page, the field is 0. The fifth byte onwards to the last usable byte can be used for the payload. Each overflow page belongs to only one record.

\subsection{Variable Length Integers}

A variable-length integer or ``varint'' is a static Huffman encoding of 64-bit twos-complement integers requires fewer bytes to represent small positive values, a common range of values found in a database (e.g. row ids, small integers, etc). A varint is between 1 and 9 bytes in length and consists of either zero or more bytes which have the high-order (most significant) bit set followed by a single byte with the high-order bit clear, or nine bytes, whichever is shorter. 

If the varint is less than nine bytes long, the lower seven bits of the bytes are used, to reconstruct the 64-bit twos-complement integer. When the varint is nine bytes long, the lower seven bits of each of the first eight bytes and all 8 bits of the ninth byte are used in reconstruction. Varints are stored in big-endian order.

Please see the appendix for an implementation of a varint decoder.

\section{Carving}

With the theoretical foundation in SQLite file formats laid out, we are in a position to begin proposing techniques for carving information from binary sources such as core dumps, file system images, and RAM memory images.

\subsection{Carving Sources}

First, we must identify a sample of souces whereby data carving of records may be carried out when performing SQLite forensics. An important point to note is that in order to carve successfully, one must understand how a source is structured. Hence, in order to ensure that the techniques listed in this section will yield positive results, a level of contiguity must exist. This level of contiguity should be, at the minimum, the size of a page.

A unique feature of SQLite that makes understanding the file format more valuable for forensics applications when compared to the more common server-client database model is its embedded property. The engine is often compiled into applications and all database operations is handled by the application itself. SQLite may be found embedded in microcontrollers, web browsers, user applications, mobile applications.

What this implies is that full SQLite database files or partial pages may be found in stack dumps, working memory, or core dumps when an application utilising the database is run or crashes. When SQLite files or pages are found in such locations, knowing techniques for carving data by hand is essential as the data or structures presented might be corrupted (e.g. remnants from a previous stack frame not quite overwritten). 

\subsection{Abstract of Carving Procedure}
\noindent The overall procedure for performing SQLite forensics may be summarised:
\begin{enumerate}
  \item Detecting a SQLite database 
    \begin{enumerate}
      \item Locate start of SQLite Database (constants in header)
      \item Parse header to find page size
    \end{enumerate}
  \item Carving
    \begin{enumerate}
      \item Determine tables schema
        \begin{enumerate}
          \item Locate page one, and parse the page header
          \item Locate cells using the cell pointer array
          \item Parse cell records
          \item Correspond fields in the record to the sqlite_master schema
        \end{enumerate}
      \item Extract table records
        \begin{enumerate}
          \item Locate B-tree leaf table pages, and parse page headers
          \item Locate cells using the cell pointer array
          \item Parse cell records
            \begin{enumerate}
              \item Follow pointers to overflow pages if the capacity of the page is inadequate to hold the record.
            \end{enumerate}
        \end{enumerate}
    \end{enumerate}
\end{enumerate}

\noindent A simple hierarchy of the structures we will encounter when carving a sqlite database is:

\textbf{SQLite Database [ Leaf Table B-tree Page [ Cell [ Record ] ], OverFlow Page ]}

It is clear that in order for us to obtain the data with fidelity in “Record” we have to begin by first unpeeling the outer layer, SQLite Database and continue on the Leaf Table B-Tree Page, then on Cell, and finally, the Record which will require further parsing in order to obtain the data from a database table row.

However, carving may still be carried out directly on the Cell level if the forensics operator recognises patterns and data structures in the raw data such as readable strings.

\subsection{Identifying a SQLite Database}

A SQLite Database can be identified with the following constant characteristics:
\begin{enumerate}
  \item A Magic Number ``0x53 0x51 0x4c 0x69 0x74 0x65 0x20 0x66 0x6f 0x72 0x6d 0x61 0x74 0x20 0x33 0x00''
  \item Page size at offset 16 is always a 2 byte big endian integer that is a power of 2 and by default is 1024 (0x04 0x00)
  \item The 3 bytes starting from offset 21 of a database header file is a constant “0x40 0x20 0x20”
  \item 100 byte header size
\end{enumerate}

This is assuming that the database is well-formed. If the magic number has been tampered with, this method of identifying a SQLite database file will not work. This step of identifying a SQLite database in a binary blob or filesystem image can be ignored in case of a non-well-formed database.

It is interesting to note that in the case where a database header cannot be found, but Leaf Table B-tree Pages can be identified, records may still be extracted. If there is a need to know the constant size of a page, the default value of 1024 bytes may be assumed or a value that is a power of 2 between 512 to 65536 bytes. 

\subsection{Identifying Leaf Table B-Tree Pages}
\noindent From what we learned in the earlier sections of this paper, a Leaf Table B-Tree Page can be identified using the following characteristics

\begin{enumerate}
\item 1-byte Constant ``0x0D'' which indicates the start of the page
\item Fixed page size as defined in database header
\item Offset 1st freeblock is less than page size constant
\item Number of Cells is more than 0 and less than Page Size/4
\item Offset to Cell Content area is equal to 0 or between 8 and Page Size.
\end{enumerate}

The page can be carved starting from ``0x0D'' to a size of the Page Size constant as defined in the database header. Assumption of Point 4 is that the minimum size of a Cell is 4 bytes. The above points make the assumption that the Leaf Table B-Tree Page is well-formed.

\subsection{Identifying and Carving Cells from Pages}

After identifying pages, the cells in the page can be identified using the cell pointer array which is after the 8-byte b-tree page header. The cell pointer array contains pointers that are made of 2-byte integers which is the offset in the b-tree page to the first byte of each cell.
According to the cell format, the first varint of the cell indicates the payload size and the next varint is the rowid. Therefore, from the cell offset in the cell pointer array, the first 2 varints will indicated the payload size and rowid respectively. 

The SQLite File Format Specification provides a formula to calculate for any payload overflows:

\begin{verbatim}
UsableSize = TotalPageSize - ReservedSize
TotalPageSize and ReservedSize are defined in the database header.
MaxLocalSize = UsableSize - 35
If PayloadSize <= MaxLocalSize then entire payload in page
else if PayloadSize > MaxLocalSize then
    MinimumLocal =  ((UsableSize-12)*32/255)-23
    LocalSize = MinimumLocal + ((PayloadSize-MinimumLocal) % 
                (UsableSize -4))
LocalSize is the size of the payload stored in the cell. 
Therefore, PayloadSize - LocalSize = OverFlowSize.
\end{verbatim}

\subsection{Carving and Parsing Records}

After, the 2 varints of the Cell is the Record where the contents of a database table row resides. From the carved Cells, the record can be parsed and data extracted. In the case that the cells are not from a leaf table b-tree page, automated tools should be able to catch exceptions rising from errors during parsing.

\noindent The following steps are to be followed in the parsing of the cell’s payload, in other words the record:

\begin{enumerate}
\item Determine header size of payload from the first varint
\item After the varint till the end of the header, determine the serial type of each column
\item Determine expected size of value from each serial type encountered
\item Parse the expected size of value as that column’s value from the body section of the payload.
\item A dummy string is stored as the value of a column that has overflows.
\end{enumerate}

Following the above steps, a record from each cell is extracted.

\section{Applications and Computer Forensics}

As smartphone usage increases, so will the number of devices utilising SQLite. Similarly, the number of browsers and other applications that require a fast and light solution for storing data client side are growing exponentially. The information contained in these SQLite databases will be valuable to forensics investigators as they may contain a high quantity of personal user data like short messages, HTTP cookies or browsing histories. As forensics investigators do work on forensic images of filesystems or RAM, there is a need to make sense out of the data, i.e. carve SQLite records from these sources. 

There has not been very detailed research on SQLite carving published nor are there any open source solutions to perform SQLite forensics. With the open sourced proof-of-concept code produced alongside this report, it is hoped that further research may be carried out and better tools can be developed from it.

\subsection{Challenges and Asides}
A challenge faced when carving SQLite databases from non-contiguous forensic images like filesystem images is in the extraction of a whole database, especially large sqlite databases. The header and different sections of the database might not take up a contiguous  chunk of hard disk space so it is difficult to simply identify a SQLite database header and expect to extract a whole fully intact database. 

However, it is possible to identify and extract individual B-tree pages but not to a hundred percentage accuracy as with all carving operations.

\section{Thoughts}

Our thoughts on the subject and the assignment after the completion of the project.

\subsection{Ku Wee Kiat}
There is very little open source tools dedicated to the carving of sqlite databases and data. In recent years, there has been a rise in interest in sqlite because of its special characteristics which led to widespread usage of sqlite db. While researching the topic of SQLite Forensics, the official sqlite documentation and especially the fileformat documentation has been a great help providing lots of details of the inside workings of sqlite. 

I have learned a lot of new things, not just related to forensics or sqlite, just from reading the documentation. For example, b-trees, varints and how useful offsets and linklists are. Looking at the development of the SQLite carving PoC code was also a good learning experience and can be used in future projects.

\paragraph{Tasks Allocated} Researching on the sqlite file format and possible forensics techniques.

\subsection{Jeremy Heng}
My first encounter with performing SQLite forensics, particularly within the realm of carving, was in a cyber security capture the flag competition hosted in Korea (Codegate 2012). There was a challenge that required you to carve deleted data from a cookie database generated by the Chrome browser. Since then, I've been rather interested in SQLite technology and have used the library myself for application projects.

During the competition, it was annoying how most of the SQLite data recovery tools we had found were proprietary. Carving by hand then was not an option as time was of the essence. This was a primary motivation to produce some source code to aid carving for this paper.

Throughout the course of this project, I have learnt many interesting things from a variety of domains. Of course, I have learnt about how SQLite stores its data but I did enjoy the esoteric things like Huffman encoding schemes and implementing them on my own. Data structures also took the centre stage with B-trees, B+trees, pointers, offsets, endianness, and structures playing a huge part of SQLite's internal workings.

Also, I have grown to respect D. Richard Hipp, the creator of SQLite, immensely for not only creating one of the best SQLite engines around but also for his altruism. SQLite is under the public domain and is open for anyone to use.

\paragraph{Tasks Allocated} Proof-of-concept writing, research, development of identification and carving techniques.

\clearpage

\lstset{
  language=Python,
  showstringspaces=false,
  formfeed=\newpage,
  tabsize=4,
  commentstyle=\itshape,
  basicstyle=\ttfamily,
  morekeywords={models, lambda, forms}
}

\newcommand{\code}[2]{
  \hrulefill
  \subsection*{#1}
  \lstinputlisting{#2}
  \vspace{2em}
}

\appendix

\section{Test SQLite Database}
We have created a test (``testdb'') database for use with the demonstrative code. The following SQL commands will create an identical copy.

\noindent\textbf{CREATE TABLE comftest (var1 integer not null, var2 integer not null, astring varchar(100) not null);}

\noindent\textbf{INSERT INTO comftest VALUES(1, 2, ``This is a string for COMF.'')}

\noindent\textbf{INSERT INTO comftest VALUES(3, 4, ``This is yet another string for COMF.'')}

\noindent\textbf{INSERT INTO comftest VALUES(5, 6, ``ss'')}

\noindent\textbf{INSERT INTO comftest VALUES(7, 3133731337, ``That number is a really huge integer!'')}


\section{Variable Length Integer Decoder}
This file implements an algorithm to decode variable length integers as used by the SQLite file format. It demonstrates the algorithm on a set of sample numbers used in documentation.

\code{readvarint.py}{../research/poc/readvarint.py}

\section{Reading pages from SQLite database}
This file demonstrates how one might parse SQLite pages. We do not actually use corrupted data. To obtain our pages, we simply split a test SQLite database along its page size.

\code{readvarint.py}{../research/poc/readpage.py}

\section{Reading cells}
This file demonstrates how one might parse cells obtained from SQLite pages.

\code{readvarint.py}{../research/poc/readcell.py}

\nocite{*}
\renewcommand\refname{References and Reading List}
\bibliographystyle{ieeetr}
\bibliography{cfpaper}

\end{document}

